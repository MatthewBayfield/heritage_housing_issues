{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Feature Engineering**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "**Perform Business requirement 2 user story task: Feature engineering ML tasks**\n",
        "* Perform categorical encoding on categorical features.\n",
        "* Perform feature selection to distill the most significant features, and also remove redundant features.\n",
        "* Carry out feature scaling/transformations to normalise the distributions of remaining features.\n",
        "* Create the data cleaning and feature engineering pipeline.\n",
        "\n",
        "## Inputs\n",
        "* cleaned train set: outputs/datasets/ml/cleaned/train_set.csv\n",
        "* cleaned test set: outputs/datasets/ml/cleaned/test_set.csv\n",
        "\n",
        "## Outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "## Change working directory"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "Working directory changed to its parent folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "os.getcwd()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Load cleaned train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_set_df = pd.read_csv(filepath_or_buffer='outputs/datasets/ml/cleaned/train_set.csv')\n",
        "test_set_df = pd.read_csv(filepath_or_buffer='outputs/datasets/ml/cleaned/test_set.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Categorical feature encoding"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the sale price correlation study notebook, the categorical features were encoded using an ordinal encoder; this was deemed most suitable since all the cateogrical features are ordinal, with an obvious ordering based around a rating.\n",
        "\n",
        "The exact same encoding will be used for the cleaned train and test sets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set_categorical_df = train_set_df.select_dtypes(include='object')\n",
        "print(train_set_categorical_df.columns)\n",
        "test_set_categorical_df = test_set_df.select_dtypes(include='object')\n",
        "test_set_categorical_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Designating the ordered categories\n",
        "bsmt_fin_type1_cat = np.array(list(reversed(['GLQ', 'ALQ', 'BLQ', 'Rec', 'LwQ', 'Unf', 'None'])))\n",
        "bsmt_exposure_cat = np.array(['None', 'No', 'Mn', 'Av', 'Gd'])\n",
        "garage_finish_cat = np.array(['None', 'Unf', 'RFn', 'Fin'])\n",
        "kitchen_quality_cat = np.array(['Po', 'Fa', 'TA', 'Gd', 'Ex'])\n",
        "\n",
        "categories = [bsmt_exposure_cat, bsmt_fin_type1_cat, garage_finish_cat, kitchen_quality_cat]\n",
        "encoder = OrdinalEncoder(categories=categories, dtype='int64')\n",
        "encoder.set_output(transform='pandas')\n",
        "\n",
        "# fitting and transforming each set\n",
        "train_set_categorical_df = encoder.fit_transform(X=train_set_categorical_df)\n",
        "train_set_df[train_set_categorical_df.columns] = train_set_categorical_df\n",
        "print(train_set_df[train_set_categorical_df.columns].head())\n",
        "test_set_categorical_df = encoder.transform(X=test_set_categorical_df)\n",
        "test_set_df[test_set_categorical_df.columns] = test_set_categorical_df\n",
        "test_set_df[test_set_categorical_df.columns].head()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initial feature selection"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It was decided to perform an initial feature selection before feature scaling, for primarily two reasons. Firstly there is quite a large number of features (23), for which performing feature scaling would be time consuming, as well as pointless for several features which have much less significance with regard to the target; this was already discovered in the sales price correlation study notebook, where a group of significant features was generated using correlation tests and PPS's applied to the whole dataset. The second reason is that as this initial selection will not use a ML model to establish the significant features, scaling is not important. \n",
        "\n",
        "Instead a similar approach to that used in the sales price correlation study involving correlation tests, but with the 'selectKBest method', will be used --- again this is not affected by scaling. \n",
        "\n",
        "After this is performed, feature-feature correlations will be assessed, and one of the features of any strongly correlated group will be dropped in order to reduce redundancy; which was seen to exist in the significant feature EDA notebook. A decision tree algorithm will be used, as this is unaffected by scaling.\n",
        "\n",
        "Feature scaling will then be performed on the most significant features, before a further feature selection will occur that relies on scale affected ML models. Since scaling has been performed, this should pose no issues."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**SelectKBest feature selection**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The SelectKBest feature selection will be performed twice, once using the Spearman correlation test, then using the phi_k correlation test."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating the score functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pingouin as pg\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\n",
        "def spearman_score_function(feature_array, target_array):\n",
        "    \"\"\"\n",
        "    Calculates spearman correlation coefficients for the train or test set.\n",
        "\n",
        "    To be used as the score function in the sklearn.feature_selection.SelectKBest function.\n",
        "\n",
        "    Args:\n",
        "        feature_array = array-like, containing train or test set feature data.\n",
        "        target_array = array-like, containing train or test set target data\n",
        "\n",
        "    Returns tuple of the spearman r values series, and the spearman p values series for the dataset.\n",
        "    \"\"\"\n",
        "    column_names = train_set_df.columns.to_list()\n",
        "    df = pd.DataFrame(data=feature_array, columns=column_names[0:-1])\n",
        "    df['SalePrice'] = target_array\n",
        "    spearman_df = df.pairwise_corr(columns=['SalePrice'], method='spearman')\n",
        "    print('Spearman coefficients')\n",
        "    print(spearman_df.sort_values(by='r')[['X', 'Y', 'r', 'p-unc']])\n",
        "    return (spearman_df['r'], spearman_df['p-unc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import phik\n",
        "from phik.phik import phik_matrix\n",
        "from phik.report import plot_correlation_matrix\n",
        "from phik.significance import significance_matrix\n",
        "\n",
        "def phik_score_function(feature_array, target_array,):\n",
        "    \"\"\"\n",
        "    Calculates phi_k correlation coefficients for the train or test set.\n",
        "\n",
        "    To be used as the score function in the sklearn.feature_selection.SelectKBest function.\n",
        "\n",
        "    Args:\n",
        "        feature_array = array-like, containing train or test set feature data.\n",
        "        target_array = array-like, containing train or test set target data\n",
        "\n",
        "    Returns tuple of the phi_k correlation values series, and the significance values series for the dataset.\n",
        "    \"\"\"\n",
        "    column_names = train_set_df.columns.to_list()\n",
        "    df = pd.DataFrame(data=feature_array, columns=column_names[0:-1])\n",
        "    df['SalePrice'] = target_array\n",
        "   \n",
        "    phik_matrix_df = phik_matrix(df)[['SalePrice']].drop('SalePrice', axis=0)\n",
        "    significance_matrix_df = significance_matrix(df)[['SalePrice']].drop('SalePrice', axis=0)\n",
        "    print('phi_k coefficients')\n",
        "    print(phik_matrix_df)\n",
        "\n",
        "    return (phik_matrix_df['SalePrice'], significance_matrix_df['SalePrice'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Will take the union of filtered out features using each score function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_out_best_features(df):\n",
        "    \"\"\"\n",
        "    Applies a SelectKBest transformer, once with a spearman score function, and then with a phi_k score function.\n",
        "\n",
        "    Args:\n",
        "        df: train or test set dataframe containing features and a target.\n",
        "\n",
        "    Returns a list of the union of the k-best-selected features generated using each score function.\n",
        "    \"\"\"\n",
        "    select_k_best = SelectKBest(score_func=spearman_score_function)\n",
        "    select_k_best.set_output(transform='pandas')\n",
        "    train_set_spearman_transformed_df = select_k_best.fit_transform(df.drop('SalePrice', axis=1), df['SalePrice'])\n",
        "\n",
        "    select_k_best = SelectKBest(score_func=phik_score_function)\n",
        "    select_k_best.set_output(transform='pandas')\n",
        "    train_set_phik_transformed_df = select_k_best.fit_transform(df.drop('SalePrice', axis=1), df['SalePrice'])\n",
        "\n",
        "    return list(set(train_set_spearman_transformed_df.columns.to_list() + train_set_phik_transformed_df.columns.to_list()))\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_features = filter_out_best_features(train_set_df)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Best features list**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Number of features:', len(selected_features))\n",
        "selected_features"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Can see that most of the selected features match those selected during the sale price correlation study notebook using the whole dataset."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now will manually transform the train set by filtering out only the selected features. Will also filter out the same features from the test set, in order to avoid data leakage by\n",
        "selecting the best features separately using the test set instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set_df = train_set_df[selected_features + ['SalePrice']]\n",
        "test_set_df = test_set_df[selected_features + ['SalePrice']]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handling redundant features"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Will select a single feature from any highly correlated feature groups, using the Spearman correlation test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "estimator = DecisionTreeRegressor(min_samples_split=10, min_samples_leaf=5, random_state=30)\n",
        "smart_correlated_transformer = SmartCorrelatedSelection(train_set_df.drop('SalePrice', axis=1).columns.to_list(),\n",
        "                                                        method='spearman', threshold=0.8, selection_method='model_performance',\n",
        "                                                        estimator=estimator, scoring='r2', cv=5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "fitting to train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "smart_correlated_transformer.fit(X=train_set_df, y=train_set_df['SalePrice'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for statement in [smart_correlated_transformer.variables,\n",
        "                  smart_correlated_transformer.correlated_feature_sets_,\n",
        "                  smart_correlated_transformer.features_to_drop_]:\n",
        "                  print(statement)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "transforming train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set_df = smart_correlated_transformer.transform(train_set_df)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "transforming test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set_df = smart_correlated_transformer.transform(test_set_df)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature scaling"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Will aim to attempt to standardise the distributions of the numeric features of the train and test sets. Will try variance-stabilizing-transformers, the standardiser method, or the normalisation method to achieve this, and evaluate the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set_df.columns.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set_numeric_df = train_set_df.drop(['OverallQual', 'KitchenQual', 'GarageFinish', 'SalePrice'], axis=1)\n",
        "test_set_numeric_df  = test_set_df.drop(['OverallQual', 'KitchenQual', 'GarageFinish', 'SalePrice'], axis=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating functions to carry out transformations, and evaluate the transformer effect, for each numeric feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def evaluate_scaling_transformation(feature_data, transformed_distribution, fig_title=None):\n",
        "    \"\"\"\n",
        "    Plots histograms, box plots, QQ plots to compare feature distributions before and after a transformation.\n",
        "\n",
        "    Args:\n",
        "        feature_data: dataframe containing untransformed numeric features.\n",
        "        transformed_distribution: dataframe containing transformed numeric features.\n",
        "        fig_title (str): Global figure title for a set of subplots.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(ncols=2, nrows=3, figsize=(10,9), tight_layout=True)\n",
        "    fig.suptitle(fig_title)\n",
        "\n",
        "    plot = sns.histplot(data=feature_data, x=feature_data.iloc[:,0], ax=axes[0][0])\n",
        "    plot.set(title='Before')\n",
        "    plot = sns.histplot(data=transformed_distribution, x=transformed_distribution.iloc[:,0], ax=axes[0][1])\n",
        "    plot.set(title='After')\n",
        "\n",
        "    plot = sns.boxplot(data=feature_data, x=feature_data.iloc[:,0], ax=axes[1][0], orient='h')\n",
        "    plot.set(title='Before')\n",
        "    plot = sns.boxplot(data=transformed_distribution, x=transformed_distribution.iloc[:,0], ax=axes[1][1], orient='h')\n",
        "    plot.set(title='After')\n",
        "\n",
        "    plot = pg.qqplot(x=feature_data.iloc[:,0], ax=axes[2][0])\n",
        "    plot.set(title='Before')\n",
        "    plot = pg.qqplot(x=transformed_distribution.iloc[:,0], ax=axes[2][1])\n",
        "    plot.set(title='After')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_all_feature_transformations(transformer, non_zero=False):\n",
        "    \"\"\"\n",
        "    Applies transformer to all numeric features of the train set. Produces plot for before and after comparisons.\n",
        "\n",
        "    Args:\n",
        "        transformer: transformer object.\n",
        "        non-zero (bool): indicates whether only features with non-zero values should be used. \n",
        "    \"\"\"\n",
        "    if not non_zero:\n",
        "        df = transformer.fit_transform(train_set_numeric_df)\n",
        "    else:\n",
        "        df = transformer.fit_transform(train_set_numeric_df.loc[:,(train_set_numeric_df > 0).all().values.tolist()])\n",
        "    \n",
        "    for feature in df.items():\n",
        "        evaluate_scaling_transformation(train_set_numeric_df[[feature[0]]], df[[feature[0]]], feature[0])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Normalisation transformers**:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Normalizer transformer:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This transformer affects transforms all features simultaneously as it transforms each instance independently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "normalizer = Normalizer()\n",
        "normalizer.set_output(transform='pandas')\n",
        "evaluate_all_feature_transformations(normalizer)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MinMaxScaler transformer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "min_max_scaler.set_output(transform='pandas')\n",
        "evaluate_all_feature_transformations(min_max_scaler)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Variance-stabilizing-transformers**:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Power transformer (exponent=0.5):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.transformation import PowerTransformer\n",
        "\n",
        "power_transformer = PowerTransformer()\n",
        "evaluate_all_feature_transformations(power_transformer)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Yeo-Johnson-Transformer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.transformation import YeoJohnsonTransformer\n",
        "\n",
        "yeo_johnson_transformer = YeoJohnsonTransformer()\n",
        "evaluate_all_feature_transformations(yeo_johnson_transformer)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Further transformations for features with all values > 0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Log transformer (base e):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.transformation import LogTransformer\n",
        "\n",
        "log_transformer = LogTransformer()\n",
        "evaluate_all_feature_transformations(log_transformer, non_zero=True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Log transformer (base 10):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.transformation import LogTransformer\n",
        "\n",
        "log_transformer = LogTransformer(base='10')\n",
        "evaluate_all_feature_transformations(log_transformer, non_zero=True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Box-Cox-Transformer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.transformation import BoxCoxTransformer\n",
        "\n",
        "box_cox_transformer = BoxCoxTransformer()\n",
        "evaluate_all_feature_transformations(box_cox_transformer, non_zero=True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Standardise transformers**:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "StandardScaler transformer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "standard_scaler = StandardScaler()\n",
        "standard_scaler.set_output(transform='pandas')\n",
        "evaluate_all_feature_transformations(standard_scaler)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Observations"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "|Feature|Observations|\n",
        "|---|---|\n",
        "|EnclosedPorchSF|No real change in normality seen. Will use normaliser to normalise.|\n",
        "|YearBuilt|Improvements in normality seen. Normaliser scales and improves normality.|\n",
        "|TotalBsmtSF|No positive changes in normality. Will use Normaliser to normalise.|\n",
        "|YearRemodAdd|Improvements in normality seen. Normaliser scales and improves normality.|\n",
        "|GarageArea|No positive changes in normality. Will use Normaliser to normalise.|\n",
        "|GrLivArea|large improvements in normality seen. Normaliser favoured as better scaling, and better normality|\n",
        "|2ndFlrSF|No improvements in normality. Use Normaliser to normalise.|\n",
        "|BsmtFinSF1|Improved normality seen. Normaliser preferable.|"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the above observations, all numeric features will be transformed using the sklearn Normaliser transformer."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Transforming numeric features in train and test sets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalizer = Normalizer()\n",
        "normalizer.set_output(transform='pandas')\n",
        "\n",
        "train_set_df[train_set_numeric_df.columns.to_list()] = normalizer.fit_transform(train_set_numeric_df)\n",
        "test_set_df[test_set_numeric_df.columns.to_list()] = normalizer.transform(test_set_numeric_df)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12 (default, Dec 24 2022, 15:19:58) \n[GCC 9.4.0]"
    },
    "orig_nbformat": 2,
    "vscode": {
      "interpreter": {
        "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

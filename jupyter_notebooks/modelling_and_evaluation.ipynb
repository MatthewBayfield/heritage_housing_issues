{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modelling and Evaluation**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "**Perform Business requirement 2 user story tasks: model selection, pipeline creation, hyperparameter tuning, model evaluation.**\n",
        "* Create initial data cleaning and engineering pipeline using information from previous notebooks.\n",
        "* Create initial modelling and evaluation pipeline using information from previous notebooks.\n",
        "* Find best model candidate.\n",
        "* Optimise chosen model through tuning and feature selection using feature importance. \n",
        "* Evaluate the model performance using performance metrics.\n",
        "* Successfully achieve $R^2 \\ge 0.75$ for the final model, to satisfy the client's success criteria, and thereby satisfy business requirement 2.\n",
        "\n",
        "\n",
        "## Inputs\n",
        "* house prices dataset: outputs/datasets/collection/house_prices.csv.\n",
        "* Information regarding the steps to include in the various pipelines, as indicated in the conclusion sections of the data cleaning and feature engineering notebooks.\n",
        "* Outlier indices list: outputs/ml/outlier_indices.pkl\n",
        "\n",
        "## Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "## Change working directory"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "Working directory changed to its parent folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "os.getcwd()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Load house price dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "house_prices_df = pd.read_csv(filepath_or_buffer='outputs/datasets/collection/house_prices.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Removing know outliers from whole dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading outlier indices list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "outlier_indices = joblib.load('outputs/ml/outlier_indices.pkl')\n",
        "outlier_indices"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Removing the instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "house_prices_df.drop(labels=outlier_indices, inplace=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create data cleaning and feature engineering pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import src.transformers_and_functions as tf\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
        "from feature_engine.selection import SmartCorrelatedSelection, DropFeatures\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_cleaning_and_feature_engineering():\n",
        "    \"\"\"\n",
        "    Constructs and returns data cleaning and feature engineering pipeline.\n",
        "    \"\"\"\n",
        "    # variables for defining pipeline\n",
        "    bsmt_fin_type1_cat = np.array(list(reversed(['GLQ', 'ALQ', 'BLQ', 'Rec', 'LwQ', 'Unf', 'None'])))\n",
        "    bsmt_exposure_cat = np.array(['None', 'No', 'Mn', 'Av', 'Gd'])\n",
        "    garage_finish_cat = np.array(['None', 'Unf', 'RFn', 'Fin'])\n",
        "    kitchen_quality_cat = np.array(['Po', 'Fa', 'TA', 'Gd', 'Ex'])\n",
        "    categories = [bsmt_exposure_cat, bsmt_fin_type1_cat, garage_finish_cat, kitchen_quality_cat]\n",
        "\n",
        "    estimator = DecisionTreeRegressor(min_samples_split=10, min_samples_leaf=5, random_state=30)\n",
        "    smart_variables = ['GrLivArea', 'GarageYrBlt', 'TotalBsmtSF', 'GarageArea', 'BsmtFinSF1',\n",
        "                       'EnclosedPorchSF', 'GarageFinish', 'KitchenQual', 'YearBuilt', 'YearRemodAdd',\n",
        "                       'OverallQual', '1stFlrSF', '2ndFlrSF']\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "                        # Data cleaning:\n",
        "                        # Missing value imputation:\n",
        "                        ('IndependentKNNImputer', tf.IndependentKNNImputer()),\n",
        "                        ('EqualFrequencyImputer', tf.EqualFrequencyImputer()),\n",
        "                        #feature engineering:\n",
        "                        # encoding:\n",
        "                        ('OrdinalEncoder', OrdinalEncoder(categories=categories, dtype='int64')),\n",
        "                        # feature number reduction\n",
        "                        ('CompositeSelectKBest'), tf.CompositeSelectKBest(),\n",
        "                        ('SmartCorrelatedSelection', SmartCorrelatedSelection(variables=smart_variables, method='spearman',\n",
        "                                                                              threshold=0.8, selection_method='model_performance',\n",
        "                                                                              estimator=estimator, scoring='r2', cv=5)),\n",
        "                        ('DropFeatures', DropFeatures('EnclosedPorchSF')),\n",
        "                        #feature scaling:\n",
        "                        ('CompositeNormaliSer', tf.CompositeNormaliser())])\n",
        "    return pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_cleaning_and_feature_engineering_pipeline = data_cleaning_and_feature_engineering()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(train_set_df, test_set_df) = train_test_split(house_prices_df, test_size=0.25, random_state=30)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scale target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_max_scaler = MinMaxScaler()\n",
        "min_max_scaler.set_output(transform='pandas')\n",
        "min_max_scaler.fit(train_set_df[['SalePrice']])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transform train set target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transformed_df = min_max_scaler.transform(train_set_df[['SalePrice']])\n",
        "train_set_df[['SalePrice']] = transformed_df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transform test set target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transformed_df = min_max_scaler.transform(test_set_df[['SalePrice']])\n",
        "test_set_df[['SalePrice']] = transformed_df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Grid Search CV"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initially a search will be done to find the most suitable algorithm using sklearn's 'GridSearchCV', using only the default hyperparameters for each algorithm.\n",
        "Hyperparmeter tuning will then be performed for this best candidate algorithm, again using 'GridSearchCV', but with multiple hyperparameter value combinations."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Best algorithm search"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a search class to handle the searches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# taken from code-Institute-Solutions/churnometer (https://github.com/Code-Institute-Solutions/churnometer)\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "            model = self.models[key]\n",
        "\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
        "                              verbose=verbose, scoring=scoring)\n",
        "            gs.fit(X, y)\n",
        "            self.grid_searches[key] = gs\n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                'estimator': key,\n",
        "                'min_score': min(scores),\n",
        "                'max_score': max(scores),\n",
        "                'mean_score': np.mean(scores),\n",
        "                'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params, **d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]\n",
        "                scores.append(r.reshape(len(params), 1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params, all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "\n",
        "        columns = ['estimator', 'min_score',\n",
        "                   'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "\n",
        "        return df[columns], self.grid_searches"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2,
    "vscode": {
      "interpreter": {
        "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modelling and Evaluation**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "**Perform Business requirement 2 user story tasks: model selection, pipeline creation, hyperparameter tuning, model evaluation.**\n",
        "* Create initial data cleaning and engineering pipeline using information from previous notebooks.\n",
        "* Create initial modelling and evaluation pipeline using information from previous notebooks.\n",
        "* Find best model candidate.\n",
        "* Optimise chosen model through tuning and feature selection using feature importance. \n",
        "* Evaluate the model performance using residual plots and performance metrics.\n",
        "* Successfully achieve $R^2 \\ge 0.75$ for the final model, to satisfy the client's success criteria, and thereby satisfy business requirement 2.\n",
        "\n",
        "\n",
        "## Inputs\n",
        "* house prices dataset: outputs/datasets/collection/house_prices.csv.\n",
        "* Information regarding the steps to include in the various pipelines, as indicated in the conclusion sections of the data cleaning and feature engineering notebooks.\n",
        "* Outlier indices list: outputs/ml/outlier_indices.pkl\n",
        "\n",
        "## Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "## Change working directory"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "Working directory changed to its parent folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "os.getcwd()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Load house price dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "house_prices_df = pd.read_csv(filepath_or_buffer='outputs/datasets/collection/house_prices.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Removing know outliers from whole dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading outlier indices list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "outlier_indices = joblib.load('outputs/ml/outlier_indices.pkl')\n",
        "outlier_indices"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Removing the instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "house_prices_df.drop(labels=outlier_indices, inplace=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create data cleaning and feature engineering pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import src.transformers_and_functions as tf\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
        "from feature_engine.selection import SmartCorrelatedSelection, DropFeatures\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_cleaning_and_feature_engineering():\n",
        "    \"\"\"\n",
        "    Constructs and returns data cleaning and feature engineering pipeline.\n",
        "    \"\"\"\n",
        "    # variables for defining pipeline\n",
        "    bsmt_fin_type1_cat = np.array(list(reversed(['GLQ', 'ALQ', 'BLQ', 'Rec', 'LwQ', 'Unf', 'None'])))\n",
        "    bsmt_exposure_cat = np.array(['None', 'No', 'Mn', 'Av', 'Gd'])\n",
        "    garage_finish_cat = np.array(['None', 'Unf', 'RFn', 'Fin'])\n",
        "    kitchen_quality_cat = np.array(['Po', 'Fa', 'TA', 'Gd', 'Ex'])\n",
        "    categories = [bsmt_exposure_cat, bsmt_fin_type1_cat, garage_finish_cat, kitchen_quality_cat]\n",
        "\n",
        "    estimator = DecisionTreeRegressor(min_samples_split=10, min_samples_leaf=5, random_state=30)\n",
        "    smart_variables = ['GrLivArea', 'GarageYrBlt', 'TotalBsmtSF', 'GarageArea', 'BsmtFinSF1',\n",
        "                       'EnclosedPorchSF', 'GarageFinish', 'KitchenQual', 'YearBuilt', 'YearRemodAdd',\n",
        "                       'OverallQual', '1stFlrSF', '2ndFlrSF']\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "                        # Data cleaning:\n",
        "                        # Missing value imputation:\n",
        "                        ('IndependentKNNImputer', tf.IndependentKNNImputer()),\n",
        "                        ('EqualFrequencyImputer', tf.EqualFrequencyImputer()),\n",
        "                        #feature engineering:\n",
        "                        # encoding:\n",
        "                        ('OrdinalEncoder', OrdinalEncoder(categories=categories, dtype='int64')),\n",
        "                        # feature number reduction\n",
        "                        ('CompositeSelectKBest'), tf.CompositeSelectKBest(),\n",
        "                        ('SmartCorrelatedSelection', SmartCorrelatedSelection(variables=smart_variables, method='spearman',\n",
        "                                                                              threshold=0.8, selection_method='model_performance',\n",
        "                                                                              estimator=estimator, scoring='r2', cv=5)),\n",
        "                        ('DropFeatures', DropFeatures('EnclosedPorchSF')),\n",
        "                        #feature scaling:\n",
        "                        ('CompositeNormaliSer', tf.CompositeNormaliser())])\n",
        "    return pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_cleaning_and_feature_engineering_pipeline = data_cleaning_and_feature_engineering()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(train_set_df, test_set_df) = train_test_split(house_prices_df, test_size=0.25, random_state=30)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scale target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_max_scaler = MinMaxScaler()\n",
        "min_max_scaler.set_output(transform='pandas')\n",
        "min_max_scaler.fit(train_set_df[['SalePrice']])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transform train set target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transformed_df = min_max_scaler.transform(train_set_df[['SalePrice']])\n",
        "train_set_df[['SalePrice']] = transformed_df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transform test set target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transformed_df = min_max_scaler.transform(test_set_df[['SalePrice']])\n",
        "test_set_df[['SalePrice']] = transformed_df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2,
    "vscode": {
      "interpreter": {
        "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

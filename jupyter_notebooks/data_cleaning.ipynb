{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data cleaning**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "**Perform Business requirement 2 user story task: Data cleaning and preparation ML tasks**\n",
        "* Find and correct if necessary invalid data.\n",
        "* Handle outliers.\n",
        "* Split dataset in to train and test subsets.\n",
        "* Impute missing data.\n",
        "* Create data cleaning pipeline.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Inputs\n",
        "* house prices dataset: outputs/datasets/collection/house_prices.csv\n",
        "\n",
        "## Outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "## Change working directory"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "Working directory changed to its parent folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "os.getcwd()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Load house price dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "house_prices_df = pd.read_csv(filepath_or_buffer='outputs/datasets/collection/house_prices.csv')\n",
        "house_prices_df.dtypes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We know from the data collection notebook, that there are no duplicates in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Invalid data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data types"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inspection of the data types for each variable, shows no discrepancies from the expectation for each variable's suitable data type."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Value ranges"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking the values for each variable are within the numeric valid range or equal to one of the categorical options, as indicated in the datasets metadata."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**First for numeric variables**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_house_prices_df = house_prices_df.select_dtypes(exclude=['object'])\n",
        "numeric_house_prices_df.columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def check_value_ranges(variable, value_range):\n",
        "    \"\"\"\n",
        "    Checks whether the non-missing values for a 'house_prices_df' numeric variable are in the valid variable range.\n",
        "\n",
        "    Args:\n",
        "        variable (str): name of variable.\n",
        "        value_range (list): [minimum value, maximum value].\n",
        "    \n",
        "    Returns a boolean indicating whether all values of the variable are in the valid range.\n",
        "\n",
        "    \"\"\"\n",
        "    variable_series = house_prices_df[variable]\n",
        "    # drop missing data\n",
        "    variable_series.dropna(inplace=True)\n",
        "    result_series = variable_series[variable_series <= value_range[1]]\n",
        "    result_series = result_series >= value_range[0]\n",
        "    return result_series.size == variable_series.size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('|Variable|Valid range|Data in valid range|')\n",
        "variable_value_ranges = {'1stFlrSF': [334, 4692], '2ndFlrSF': [0, 2065], 'BedroomAbvGr': [0, 8], 'BsmtFinSF1': [0, 5644],\n",
        "                         'BsmtUnfSF': [0, 2336], 'TotalBsmtSF': [0, 6110], 'GarageArea': [0, 1418], 'GarageYrBlt': [1900, 2010],\n",
        "                         'GrLivArea': [334, 5642], 'LotArea': [1300, 215245], 'LotFrontage': [21, 313], 'MasVnrArea': [0, 1600],\n",
        "                         'EnclosedPorchSF': [0, 286], 'OpenPorchSF': [0, 547], 'OverallCond': [1, 10], 'OverallQual': [1,10],\n",
        "                         'WoodDeckSF': [0, 736], 'YearBuilt': [1872, 2010], 'YearRemodAdd': [1950, 2010], 'SalePrice': [34900, 755000]}\n",
        "\n",
        "for variable in numeric_house_prices_df.columns:\n",
        "    print(f'{variable}|', f'{variable_value_ranges[variable]}|', check_value_ranges(variable, variable_value_ranges[variable]))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All non-missing values are in the valid range for each numeric variable."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Now for categorical variables**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_house_prices_df = house_prices_df.select_dtypes(include=['object'])\n",
        "categorical_house_prices_df.columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# include NaN as a valid value \n",
        "result_df = categorical_house_prices_df.isin({'BsmtExposure': ['Gd', 'Av', 'Mn', 'No', 'None', np.nan], 'BsmtFinType1': ['GLQ', 'ALQ', 'BLQ', 'Rec', 'LwQ', 'Unf', 'None', np.nan],\n",
        "                                  'GarageFinish': ['Fin', 'RFn', 'Unf', 'None', np.nan], 'KitchenQual': ['Ex', 'Gd', 'TA', 'Fa', 'Po', np.nan]})\n",
        "for col in result_df.columns:\n",
        "    print(result_df[col].value_counts())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All values are valid for the categorical variables (allowing for missing data)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outliers"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Determined from the significant features EDA notebook that for the most significant continuous numeric features in relation to sale price, there were several instances whose vector components were outliers in at least 50% of the continuous features, thus making them more likely multivariate outliers. What's more it was discovered that the components of these instances corresponded to the extremest outliers for multiple features, supporting the idea of a correlation between the number of features for which an instance's component is an outlier, and the extremity of the outliers."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Outliers for each feature (using the whole dataset) were determined using the IQR method, and the indices of the outliers tracked and counted to determine if the same instance gave rise to outliers for other features. It is common that the dataset is first split into train and test sets before handling outliers, perhaps using a transformer such as winsorize; the idea being to minimise the risk of data leakage. However arguably an outlier in the whole data set (at least the most extreme ones) will still be an outlier in a sample of the distribution (if it is present). Also it could be argued that such values if particularly extreme, and depending on the context of the dataset and business aims, offer no value, and potentially impact the ML algorithms. Therefore for this dataset the outliers will be trimmed from the whole dataset. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Adding the outlier related functions from the significant feature EDA notebook.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# taken from significant_feature_EDA.ipynb\n",
        "def locate_single_feature_outliers(feature, df):\n",
        "    \"\"\"\n",
        "    Locates outliers for a feature in a dataframe (containing only numeric features) using the IQR method.\n",
        "\n",
        "    Args:\n",
        "        feature (str): the feature name.\n",
        "        df: dataframe containing the feature.\n",
        "\n",
        "    Returns a list of indices corresponding to the dataframe indices of the outliers.\n",
        "    \"\"\"\n",
        "    sample = df[feature]\n",
        "    mean = sample.mean()\n",
        "    SD = sample.std()\n",
        "    Q1 = sample.quantile(q=0.25)\n",
        "    Q3 = sample.quantile(q=0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    def return_outliers(instance):\n",
        "        return instance > IQR*1.5 + Q3 or instance < Q1 - 1.5*IQR\n",
        "    result = sample.apply(func=return_outliers)\n",
        "    return result[result == True].index.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# taken from significant_feature_EDA.ipynb\n",
        "def locate_all_feature_outliers(df):\n",
        "    \"\"\"\n",
        "    Amalgamates into a single list, the dataframe (containing only numeric features) indices corresponding to all outliers of features in a dataframe.\n",
        "\n",
        "    args:\n",
        "        df: dataframe containing numeric features.\n",
        "\n",
        "    Returns a list. It contains a series with index corresponding to the index of an outlier, and a column value\n",
        "    corresponding to the number of times the instance is a common outlier across all features. Also contains\n",
        "    a value_counts series for the series; finally contains a float for the number of features in the dataframe.\n",
        "    \"\"\"\n",
        "    outlier_indices = []\n",
        "    for col in df.columns:\n",
        "        found_ouliers = locate_single_feature_outliers(col, df)\n",
        "        outlier_indices.extend(found_ouliers)\n",
        "    index_freq = np.array(outlier_indices)\n",
        "    index_count = np.unique(index_freq, return_counts=True)\n",
        "    index_count_series = pd.Series(data=index_count[1], index=index_count[0]).sort_values(ascending=False)\n",
        "    return [index_count_series, index_count_series.value_counts().sort_values(), df.columns.size]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rediscovering the outlier instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "continuous_numeric_features = ['1stFlrSF', '2ndFlrSF', 'BsmtFinSF1', 'GarageArea', 'GrLivArea',\n",
        "                               'LotArea',\n",
        "                               'LotFrontage',\n",
        "                               'MasVnrArea',\n",
        "                               'OpenPorchSF',\n",
        "                               'TotalBsmtSF']\n",
        "outlier_series, outlier_series_unique_count, total_feature_num = locate_all_feature_outliers(house_prices_df[continuous_numeric_features])\n",
        "print('\\n','Instances whose component values correspond to potential outliers in more than 50% of continuous numeric features:')\n",
        "house_prices_df[continuous_numeric_features].loc[outlier_series[outlier_series > 5].index.tolist()]   "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Removing the instances from the whole dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "house_prices_df.drop(labels=house_prices_df.loc[outlier_series[outlier_series > 5].index.tolist()].index.tolist(), inplace=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2,
    "vscode": {
      "interpreter": {
        "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
